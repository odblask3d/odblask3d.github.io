---
layout: page
title: About
permalink: /about/
---

![Phone image](images/apple.webp)

We are convinced that we already have a powerful 3D scanner right in our pocket, but we just do not use its abilities.
Based on our observations of high-end photogrammetry approaches, we know that 3D scans with millimeter accuracy are achievable — in a cumbersome and costly way.

Our smartphones come with various sensors (IMU, LiDAR/TrueDepth) apart from the camera and many smartphone cameras have in-built abilities that professional single purpose cameras do not have (such as AI enhanced Portrait Modes).

While __Android__ tends to enable more open-source projects providing insights 'under the hood', __Apple iOS__ provides a uniform user-experience with substantially less variety in devices. In other words, less tailoring per device is needed as there are only a few iPhones, currently only higher-end versions providing all sensors (LiDAR, FaceID/TrueDepth) but the development process is uniform.

The competition tries to force traditional photogrammetry approaches onto the smartphone with only limited output quality.
We want to use the IMU guide TrueDepth data to generate high quality results that professional engineers, designers, artists can use straight away without 
* Having to buy costly hardware 
* Pay for a service that ist costly and time-consuming 
* Not even having to buy a single add-on to be placed on or near the phone.

That’s what makes Odblask<sup>*</sup> unique.

<sup>* Note that Odblask is derived from the Polish version of reflection</sup>

